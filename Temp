# src/train.py

import os
import joblib
import pandas as pd
from datetime import timedelta
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Local imports
from extract import load_csv
from labelers import (
    label_anomaly,
    label_card_share,
    label_duration,
    label_low_swipe,
    label_exit_first,
    label_simultaneous,
)

# -----------------------------------------------------------------------------
# Helper to apply all labelers in sequence
# -----------------------------------------------------------------------------
def apply_all_labelers(df: pd.DataFrame) -> pd.DataFrame:
    """
    Apply each labeling function in turn, merging the results back into a single DataFrame.
    Returns a DataFrame containing the original columns plus new label columns.
    """

    # 1) Start with anomaly labels
    df_anomaly = label_anomaly(df)

    # 2) Next, card_share
    df_card_share = label_card_share(df_anomaly)

    # 3) Duration labels (per-day aggregation)
    df_duration = label_duration(df_card_share)

    # 4) Low-swipe labels (per-day)
    df_low_swipe = label_low_swipe(df_card_share)

    # 5) Exit-first labels (per-day)
    df_exit_first = label_exit_first(df_card_share)

    # 6) Simultaneous labels (per-swipe)
    df_simultaneous = label_simultaneous(df_card_share)

    # Now merge per-swipe labels back into a single swipe-level DataFrame:
    # df_card_share already contains anomaly, card_share, and simultaneous.
    df_merged = df_card_share.copy()

    # Merge in duration-based flags (short_stay, long_stay) by (EmployeeID, Dateonly)
    df_merged = df_merged.merge(
        df_duration[["EmployeeID", "Dateonly", "short_stay", "long_stay"]],
        on=["EmployeeID", "Dateonly"],
        how="left",
    )

    # Merge in low-swipe flags (one_swipe, two_swipe)
    df_merged = df_merged.merge(
        df_low_swipe[["EmployeeID", "Dateonly", "one_swipe", "two_swipe"]],
        on=["EmployeeID", "Dateonly"],
        how="left",
    )

    # Merge in exit_first flag
    df_merged = df_merged.merge(
        df_exit_first[["EmployeeID", "Dateonly", "exit_first"]],
        on=["EmployeeID", "Dateonly"],
        how="left",
    )

    # Finally, ensure any missing label values become False, and cast to pandas' BooleanDtype.
    for col in [
        "anomaly",
        "card_share",
        "simultaneous",
        "one_swipe",
        "two_swipe",
        "exit_first",
        "short_stay",
        "long_stay",
    ]:
        if col not in df_merged.columns:
            df_merged[col] = False
        # Fill missing with False, then cast to the nullable BooleanDtype
        df_merged[col] = df_merged[col].fillna(False).astype("boolean")

    return df_merged


# -----------------------------------------------------------------------------
# Feature Engineering
# -----------------------------------------------------------------------------
def engineer_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Given the labeled DataFrame, create additional features for model training.
    Returns a new DataFrame (df_features) ready for ML.
    """

    df = df.copy()

    # 1) Ensure timestamp is datetime and not an index
    df["LocaleMessageTime"] = pd.to_datetime(df["LocaleMessageTime"], errors="coerce")
    df = df.dropna(subset=["LocaleMessageTime"])

    # 2) Create some time-based features
    df["hour"] = df["LocaleMessageTime"].dt.hour
    df["weekday"] = df["LocaleMessageTime"].dt.weekday  # Monday=0, Sunday=6

    # 3) Duration features already exist in df: short_stay, long_stay (as BooleanDtype)

    # 4) Fill missing 'zone' with 'Unknown' if needed
    if "zone" not in df.columns:
        df["zone"] = "Unknown"
    else:
        df["zone"] = df["zone"].fillna("Unknown")

    # 5) Convert categorical/text columns to simpler numeric or one-hot if desired
    df["PersonnelType"] = df["PersonnelType"].fillna("Unknown")
    df["personnel_type_code"] = df["PersonnelType"].astype("category").cat.codes

    # 6) Create a binary target: is_anomaly (1 if anomaly=True, else 0)
    df["is_anomaly"] = df["anomaly"].astype(int)

    # 7) Assemble final feature set
    feature_columns = [
        "hour",
        "weekday",
        "personnel_type_code",
        "swipe_count_rolling",
        "one_swipe",
        "two_swipe",
        "exit_first",
        "short_stay",
        "long_stay",
        "simultaneous",
        "card_share",
    ]

    # Ensure all feature columns exist
    for col in feature_columns:
        if col not in df.columns:
            # If a boolean flag is missing, fill with False; else numeric fill 0
            if col in [
                "one_swipe",
                "two_swipe",
                "exit_first",
                "short_stay",
                "long_stay",
                "simultaneous",
                "card_share",
            ]:
                df[col] = False
            else:
                df[col] = 0

    # Cast boolean flags to int (0/1)
    bool_cols = [
        "one_swipe",
        "two_swipe",
        "exit_first",
        "short_stay",
        "long_stay",
        "simultaneous",
        "card_share",
    ]
    for bool_col in bool_cols:
        df[bool_col] = df[bool_col].astype(int)

    # Build the feature-matrix (X) and the target vector (y)
    df_features = df[feature_columns + ["is_anomaly"]].copy()

    return df_features


# -----------------------------------------------------------------------------
# Main training routine
# -----------------------------------------------------------------------------
def build_and_save_model():
    """
    1) Load raw CSV, apply all labelers, engineer features.
    2) Train a RandomForestClassifier to detect anomalies.
    3) Save the trained model to disk (models/rf_model.joblib).
    """
    # Step 1: Load data (this will call extract.load_csv)
    df_raw = load_csv()

    # Step 2: Apply labeling functions
    df_labeled = apply_all_labelers(df_raw)

    # Step 3: Engineer features and target
    df_features = engineer_features(df_labeled)

    # Step 4: Split into train/test
    X = df_features.drop(columns=["is_anomaly"])
    y = df_features["is_anomaly"]
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # Step 5: Train a simple RandomForestClassifier
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_train, y_train)

    # Step 6: Evaluate on the test set
    y_pred = clf.predict(X_test)
    print("\n[Classification Report on Test Set]")
    print(classification_report(y_test, y_pred))

    # Step 7: Save the model to disk
    os.makedirs(
        os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "models")),
        exist_ok=True,
    )
    model_path = os.path.abspath(
        os.path.join(os.path.dirname(__file__), "..", "models", "rf_model.joblib")
    )
    joblib.dump(clf, model_path)
    print(f"✅ Model saved to: {model_path}")


# -----------------------------------------------------------------------------
# If this script is invoked directly, run training.
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    build_and_save_model()














PS C:\Users\W0024618\Desktop\ai-employee-security\src> python train.py
⏱️  Detected timestamp column: 'LocaleMessageTime'
C:\Users\W0024618\Desktop\ai-employee-security\src\extract.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  df["LocaleMessageTime"] = pd.to_datetime(
C:\Users\W0024618\Desktop\ai-employee-security\src\train.py:88: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  df_merged[col] = df_merged[col].fillna(False).astype("boolean")

[Classification Report on Test Set]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     44371
           1       1.00      1.00      1.00     17736

    accuracy                           1.00     62107
   macro avg       1.00      1.00      1.00     62107
weighted avg       1.00      1.00      1.00     62107

✅ Model saved to: C:\Users\W0024618\Desktop\ai-employee-security\models\rf_model.joblib
