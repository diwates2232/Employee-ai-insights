# src/test_labelers.py

import sys
import os
from pathlib import Path

# ── Add project root to PYTHONPATH so we can import src.labelers ─────────
FILE = Path(__file__).resolve()
PROJECT_ROOT = FILE.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ── Load the pickled logs ───────────────────────────────────────────────────
import pandas as pd

logs_path = PROJECT_ROOT / "data" / "logs.pkl"
df = pd.read_pickle(logs_path)
print("Original columns:", df.columns.tolist())

# ── Import your labelers ────────────────────────────────────────────────────
from src.labelers import (
    label_anomaly,
    label_card_share,
    label_duration,
    label_low_swipe,
    label_exit_first,
    label_simultaneous,
    # add other labelers as you implement them
)

# ── Apply each labeler ──────────────────────────────────────────────────────
df_anom         = label_anomaly(df)
df_card_share   = label_card_share(df)
df_duration     = label_duration(df)
df_low_swipe    = label_low_swipe(df)
df_exit_first   = label_exit_first(df)
df_simultaneous = label_simultaneous(df)

# ── Inspect the new columns ──────────────────────────────────────────────────
print("\nAfter label_anomaly, columns:", df_anom.columns.tolist())
print("Sample anomaly flags:\n", df_anom[["EmployeeID", "LocaleMessageTime", "anomaly"]].head())

print("\nAfter label_card_share, columns:", df_card_share.columns.tolist())
print("Sample card_share flags:\n", df_card_share[["EmployeeID", "CardNumber", "card_share"]].head())

print("\nDuration output columns:", df_duration.columns.tolist())
print(df_duration.head())

print("\nLow-swipe output columns:", df_low_swipe.columns.tolist())
print(df_low_swipe.head())

print("\nFirst-swipe-out output columns:", df_exit_first.columns.tolist())
print(df_exit_first.head())

print("\nSimultaneous output columns:", df_simultaneous.columns.tolist())
print(df_simultaneous[df_simultaneous["simultaneous"]].head())













# src/test_labelers.py

import pandas as pd
from pathlib import Path

# 1) Load the pickled logs
PROJECT_ROOT = Path(__file__).parent.parent
logs_path    = PROJECT_ROOT / "data" / "logs.pkl"
df = pd.read_pickle(logs_path)
print("Original columns:", df.columns.tolist())

# 2) Import your labelers
from src.labelers import (
    label_anomaly,
    label_card_share,
    label_duration,
    label_low_swipe,
    label_exit_first,
    label_simultaneous,
    # … import additional labelers as you implement them …
)

# 3) Apply each labeler (they each return a new DataFrame or merge internally)
df_anom          = label_anomaly(df)
df_card_share    = label_card_share(df)
df_duration      = label_duration(df)
df_low_swipe     = label_low_swipe(df)
df_exit_first    = label_exit_first(df)
df_simultaneous  = label_simultaneous(df)

# 4) Inspect the new columns
print("\nAfter label_anomaly, columns:", df_anom.columns.tolist())
print("Sample anomaly flags:\n", df_anom[["EmployeeID", "LocaleMessageTime", "anomaly"]].head())

print("\nAfter label_card_share, columns:", df_card_share.columns.tolist())
print("Sample card_share flags:\n", df_card_share[["EmployeeID", "CardNumber", "card_share"]].head())

print("\nDuration output columns:", df_duration.columns.tolist())
print(df_duration.head())

print("\nLow-swipe output columns:", df_low_swipe.columns.tolist())
print(df_low_swipe.head())

print("\nFirst-swipe-out output columns:", df_exit_first.columns.tolist())
print(df_exit_first.head())

print("\nSimultaneous output columns:", df_simultaneous.columns.tolist())
print(df_simultaneous[df_simultaneous["simultaneous"]].head())









# src/labelers.py

import pandas as pd
from datetime import timedelta

def label_anomaly(df: pd.DataFrame, window_minutes: int = 10, max_swipes: int = 5) -> pd.DataFrame:
    """
    Label 'anomaly' if an employee has more than `max_swipes` within `window_minutes`.
    """
    df = df.sort_values("LocaleMessageTime").copy()
    # Count swipes in rolling window per employee
    df["swipe_count_rolling"] = (
        df.groupby("EmployeeID")["LocaleMessageTime"]
          .rolling(f"{window_minutes}min")
          .count()
          .reset_index(0, drop=True)
    )
    df["anomaly"] = df["swipe_count_rolling"] > max_swipes
    return df

def label_card_share(df: pd.DataFrame, window: timedelta = timedelta(minutes=5)) -> pd.DataFrame:
    """
    Label 'card_share' when two different EmployeeIDs use the same CardNumber within `window`.
    """
    df = df.sort_values("LocaleMessageTime").copy()
    df["prev_employee"] = df.groupby("CardNumber")["EmployeeID"].shift(1)
    df["prev_time"]     = df.groupby("CardNumber")["LocaleMessageTime"].shift(1)
    df["card_share"] = (
        (df["EmployeeID"] != df["prev_employee"]) &
        (df["LocaleMessageTime"] - df["prev_time"] <= window)
    )
    return df

def label_duration(df: pd.DataFrame) -> pd.DataFrame:
    """
    Compute duration per day and label 'short_stay' (<1h) and 'long_stay' (>10h).
    """
    # Aggregate per EmployeeID & Dateonly
    agg = (
        df.groupby(["EmployeeID", "Dateonly"])["LocaleMessageTime"]
          .agg(["min", "max", "count"])
          .rename(columns={"min": "first_swipe", "max": "last_swipe", "count": "swipe_count"})
          .reset_index()
    )
    agg["duration_hours"] = (agg["last_swipe"] - agg["first_swipe"]).dt.total_seconds() / 3600
    agg["short_stay"] = agg["duration_hours"] < 1
    agg["long_stay"]  = agg["duration_hours"] > 10
    return agg

def label_low_swipe(df: pd.DataFrame) -> pd.DataFrame:
    """
    Label 'one_swipe' or 'two_swipe' if total swipes per day ≤ 2.
    """
    counts = (
        df.groupby(["EmployeeID", "Dateonly"])
          .size()
          .reset_index(name="swipe_count")
    )
    counts["one_swipe"] = counts["swipe_count"] == 1
    counts["two_swipe"] = counts["swipe_count"] == 2
    return counts

def label_exit_first(df: pd.DataFrame) -> pd.DataFrame:
    """
    Label 'exit_first' if the first swipe of the day is OutDirection.
    """
    first = (
        df.sort_values("LocaleMessageTime")
          .groupby(["EmployeeID", "Dateonly"])
          .first()
          .reset_index()
    )
    first["exit_first"] = first["Direction"] == "OutDirection"
    return first

def label_simultaneous(df: pd.DataFrame) -> pd.DataFrame:
    """
    Label 'simultaneous' when two different EmployeeIDs swipe same Door at same time.
    """
    dup = (
        df.groupby(["Door", "LocaleMessageTime"])["EmployeeID"]
          .nunique()
          .reset_index(name="user_count")
    )
    dup["simultaneous"] = dup["user_count"] > 1
    # Merge back
    return df.merge(dup[["Door", "LocaleMessageTime", "simultaneous"]], 
                    on=["Door", "LocaleMessageTime"], how="left")

# TODO: Implement the remaining label functions:
# 7. label_rejection_trend()
# 8. label_unauthorized_access()
# 9. label_after_hours()
# 10. label_rapid_hop()
# 11. label_loiter_after_hours()
# 12. label_weekend_access()
# 13. label_holiday_access()
# 14. label_no_exit()
# 15. label_rapid_in_out()
# 16. label_zone_pingpong()
# 17. label_new_door()
# 18. label_high_volume()
# 19. label_time_window_violation()
# 20. label_failed_access_trend()









# src/extract.py

import pandas as pd
import os
import re

# Project paths
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))
DATA_DIR     = os.path.join(PROJECT_ROOT, "data")
CSV_NAME     = "access_logs.csv"
PICKLE_NAME  = "logs.pkl"

def detect_timestamp_column(path: str) -> str:
    """
    Load zero rows to inspect column names, then pick
    the first one containing 'time' (case-insensitive).
    """
    df_head = pd.read_csv(path, nrows=0)
    for col in df_head.columns:
        if re.search(r"time", col, re.IGNORECASE):
            return col
    # fallback to first column
    return df_head.columns[0]

def load_csv(filename: str = CSV_NAME) -> pd.DataFrame:
    csv_path = os.path.join(DATA_DIR, filename)
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"No such file: {csv_path}")

    # 1) Detect the timestamp column
    ts_col = detect_timestamp_column(csv_path)
    print(f"⏱️  Detected timestamp column: '{ts_col}'")

    # 2) Read CSV, parsing only that column as datetime
    df = pd.read_csv(csv_path, parse_dates=[ts_col])

    # 3) Rename it to a uniform name
    df = df.rename(columns={ts_col: "LocaleMessageTime"})

    # 4) Derive date-only and time-only columns
    df["Dateonly"]   = df["LocaleMessageTime"].dt.date
    df["Swipe_Time"] = df["LocaleMessageTime"].dt.time

    return df

def save_pickle(df: pd.DataFrame, filename: str = PICKLE_NAME):
    path = os.path.join(DATA_DIR, filename)
    df.to_pickle(path)
    print(f"✅ Saved DataFrame with {len(df)} rows to {path}")

if __name__ == "__main__":
    # Load & parse
    df = load_csv()
    # Sanity checks
    print("✅ Rows loaded:", len(df))
    print(df.head())
    # Save for downstream
    save_pickle(df)











ai-employee-security/data/access_logs.csv





# src/extract.py

import pandas as pd
import os
import re

# Compute project root (one level up from this file)
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))
DATA_DIR     = os.path.join(PROJECT_ROOT, "data")
CSV_NAME     = "access_logs.csv"
PICKLE_NAME  = "logs.pkl"

def detect_timestamp_column(path: str) -> str:
    """
    Read the header of the CSV and pick the first column
    whose name contains 'time' (case-insensitive).
    """
    with open(path, 'r', encoding='utf-8') as f:
        header = f.readline().strip()
    cols = [c.strip() for c in header.split(',')]
    for c in cols:
        if re.search(r"time", c, re.IGNORECASE):
            return c
    # fallback to first column
    return cols[0]

def load_csv(filename: str = CSV_NAME) -> pd.DataFrame:
    """
    Load raw access logs from CSV in data/ folder,
    auto-detect timestamp column, parse it, and extract
    Dateonly and Swipe_Time columns.
    """
    csv_path = os.path.join(DATA_DIR, filename)
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"No such file: {csv_path}")

    # 1) Detect which column holds the timestamp
    ts_col = detect_timestamp_column(csv_path)
    print(f"⏱️  Detected timestamp column: '{ts_col}'")

    # 2) Read CSV, parsing the timestamp column
    df = pd.read_csv(csv_path, parse_dates=[ts_col])

    # 3) Rename it uniformly
    df = df.rename(columns={ts_col: "LocaleMessageTime"})

    # 4) Derive separate date and time columns
    df["Dateonly"]   = df["LocaleMessageTime"].dt.date
    df["Swipe_Time"] = df["LocaleMessageTime"].dt.time

    return df

def save_pickle(df: pd.DataFrame, filename: str = PICKLE_NAME):
    path = os.path.join(DATA_DIR, filename)
    df.to_pickle(path)
    print(f"✅ Saved DataFrame with {len(df)} rows to {path}")

if __name__ == "__main__":
    # 1) Load raw CSV
    df = load_csv()

    # 2) Quick sanity check
    print("✅ Rows loaded:", len(df))
    print(df.head())

    # 3) Save for fast reload
    save_pickle(df)














import pandas as pd
import os

# Compute project root (one level up from this file)
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))

def load_csv(filename: str = "access_logs.csv") -> pd.DataFrame:
    """
    Load raw access logs from CSV in data/ folder,
    parse timestamps, and extract Dateonly and Swipe_Time.
    """
    data_path = os.path.join(PROJECT_ROOT, "data", filename)
    # Correct function name is read_csv
    df = pd.read_csv(data_path, parse_dates=["LocaleMessageTime"])
    df["Dateonly"]   = df["LocaleMessageTime"].dt.date
    df["Swipe_Time"] = df["LocaleMessageTime"].dt.time
    return df

def save_pickle(df: pd.DataFrame, filename: str = "logs.pkl"):
    path = os.path.join(PROJECT_ROOT, "data", filename)
    df.to_pickle(path)
    print(f"✅ Saved DataFrame with {len(df)} rows to {path}")

if __name__ == "__main__":
    df = load_csv()  # will look at data/access_logs.csv
    print("✅ Rows loaded:", len(df))
    print(df.head())
    save_pickle(df)






dir .\data\access_logs.csv




# Example: if it’s sitting on your Desktop
Copy-Item C:\Users\W0024618\Desktop\access_logs.csv .\data\




# src/extract.py

import pandas as pd
import os

# Compute the project root (one level up from this file)
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))

def load_csv(filename: str = "access_logs.csv") -> pd.DataFrame:
    """
    Load raw access logs from CSV in data/ folder,
    parse timestamps, and extract Dateonly and Swipe_Time.
    """
    data_path = os.path.join(PROJECT_ROOT, "data", filename)
    df = pd.read_csv(data_path, parse_dates=["LocaleMessageTime"])
    
    df["Dateonly"]   = df["LocaleMessageTime"].dt.date
    df["Swipe_Time"] = df["LocaleMessageTime"].dt.time
    return df

def save_pickle(df: pd.DataFrame, filename: str = "logs.pkl"):
    path = os.path.join(PROJECT_ROOT, "data", filename)
    df.to_pickle(path)
    print(f"✅ Saved DataFrame with {len(df)} rows to {path}")

if __name__ == "__main__":
    df = load_csv()  # will look at data/access_logs.csv
    print("✅ Rows loaded:", len(df))
    print(df.head())
    save_pickle(df)







// controllers/liveOccupancyController.js

const { poolConnect, pool, sql } = require('../config/db');
const mapDoorToZone = require('../data/doorZoneMap');

async function fetchNewEvents(since) {
  const req = pool.request();
  req.input('since', sql.DateTime2, since);
  const result = await req.query(`
    WITH CombinedQuery AS (
      SELECT 
        DATEADD(MINUTE, -1 * t1.[MessageLocaleOffset], t1.[MessageUTC]) AS LocaleMessageTime,
        t1.ObjectName1,
        CASE 
          WHEN t3.Name IN ('Contractor','Terminated Contractor') THEN t2.Text12
          ELSE CAST(t2.Int1 AS NVARCHAR)
        END AS EmployeeID,
        t3.Name AS PersonnelType,
        COALESCE(
          TRY_CAST(t_xml.XmlMessage AS XML).value('(/LogMessage/CHUID/Card)[1]','varchar(50)'),
          TRY_CAST(t_xml.XmlMessage AS XML).value('(/LogMessage/CHUID)[1]','varchar(50)'),
          SCard.[value]
        ) AS CardNumber,
        t5_admit.value AS AdmitCode,
        t5_dir.value   AS Direction,
        t1.ObjectName2 AS Door
      FROM [ACVSUJournal_00010020].[dbo].[ACVSUJournalLog] t1
      LEFT JOIN [ACVSCore].[Access].[Personnel]      t2 ON t1.ObjectIdentity1 = t2.GUID
      LEFT JOIN [ACVSCore].[Access].[PersonnelType]  t3 ON t2.PersonnelTypeId = t3.ObjectID
      LEFT JOIN [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred] t5_admit
        ON t1.XmlGUID = t5_admit.GUID AND t5_admit.Name = 'AdmitCode'
      LEFT JOIN [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred] t5_dir
        ON t1.XmlGUID = t5_dir.GUID AND t5_dir.Value IN ('InDirection','OutDirection')
      LEFT JOIN [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxml] t_xml
        ON t1.XmlGUID = t_xml.GUID
      LEFT JOIN (
        SELECT GUID, [value]
        FROM [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred]
        WHERE [Name] IN ('Card','CHUID')
      ) AS SCard
        ON t1.XmlGUID = SCard.GUID
      WHERE
        t1.MessageType = 'CardAdmitted'
        AND t1.PartitionName2 = 'APAC.Default'
        AND DATEADD(MINUTE, -1 * t1.MessageLocaleOffset, t1.MessageUTC) > @since
    )
    SELECT
      LocaleMessageTime,
      CONVERT(VARCHAR(10), LocaleMessageTime, 23) AS Dateonly,
      CONVERT(VARCHAR(8),  LocaleMessageTime, 108) AS Swipe_Time,
      EmployeeID,
      ObjectName1,
      PersonnelType,
      CardNumber,
      AdmitCode,
      Direction,
      Door
    FROM CombinedQuery
    ORDER BY LocaleMessageTime ASC;
  `);

  return result.recordset;
}

async function buildOccupancy(allEvents) {
  const current = {};
  for (const evt of allEvents) {
    const {
      EmployeeID,
      ObjectName1,
      PersonnelType,
      CardNumber,
      Dateonly,
      Swipe_Time,
      Direction,
      Door
    } = evt;

    let zone = mapDoorToZone(Door, Direction) || 'Unknown Zone';

    if (Direction === 'InDirection') {
      current[EmployeeID] = {
        Dateonly,
        Swipe_Time,
        EmployeeID,
        ObjectName1,
        CardNumber,
        PersonnelType,
        zone
      };
    } else {
      delete current[EmployeeID];
    }
  }

  const zoneMap = {};
  for (const emp of Object.values(current)) {
    zoneMap[emp.zone] = zoneMap[emp.zone] || [];
    zoneMap[emp.zone].push(emp);
  }

  const summary = Object.entries(zoneMap).map(([zone, emps]) => ({
    zone,
    count: emps.length
  }));

  return { asOf: new Date().toISOString(), summary, details: zoneMap };
}

exports.getLiveOccupancy = async (req, res) => {
  try {
    await poolConnect;

    res.writeHead(200, {
      'Content-Type':      'text/event-stream',
      'Cache-Control':     'no-cache',
      'Connection':        'keep-alive'
    });
    res.write('\n');

    let lastSeen = new Date(Date.now() - 1000 * 60 * 60); // start one hour back (or adjust)

    // keep a running list of all in-scope events to compute occupancy
    const allEvents = [];

    const checkForNew = async () => {
      const newEvents = await fetchNewEvents(lastSeen);
      if (newEvents.length > 0) {
        // update our lastSeen to the timestamp of the newest event
        lastSeen = newEvents[newEvents.length - 1].LocaleMessageTime;
        // add them to the master list
        allEvents.push(...newEvents);
        // rebuild occupancy and push
        const payload = await buildOccupancy(allEvents);
        res.write(`data: ${JSON.stringify(payload)}\n\n`);
      }
    };

    // initial emit (empty or existing in last hour)
    {
      const recent = await fetchNewEvents(new Date(Date.now() - 1000*60*60));
      if (recent.length) {
        lastSeen = recent[recent.length-1].LocaleMessageTime;
        allEvents.push(...recent);
      }
      const initial = await buildOccupancy(allEvents);
      res.write(`data: ${JSON.stringify(initial)}\n\n`);
    }

    const interval = setInterval(checkForNew, 1000);

    req.on('close', () => clearInterval(interval));

  } catch (err) {
    console.error('Live occupancy SSE error:', err);
    res.status(500).json({ error: 'Internal Server Error' });
  }
};














// controllers/liveOccupancyController.js

const { poolConnect, pool } = require('../config/db');
const mapDoorToZone = require('../data/doorZoneMap');

// Encapsulate your query + mapping logic into a reusable function
async function fetchLiveOccupancyData() {
  const request = pool.request();
  const result = await request.query(`
    WITH CombinedQuery AS (
      /* … your full SQL from before, including t5_dir, t5_admit, etc. … */
    )
    SELECT
      CONVERT(VARCHAR(10), LocaleMessageTime, 23) AS Dateonly,
      CONVERT(VARCHAR(8),  LocaleMessageTime, 108) AS Swipe_Time,
      EmployeeID,
      ObjectName1,
      PersonnelType,
      CardNumber,
      AdmitCode,
      Direction,
      Door
    FROM CombinedQuery
    WHERE
      LocaleMessageTime >= DATEADD(HOUR, -24, GETDATE())
      AND AdmitCode = 'Admit'
      AND Direction IN ('InDirection','OutDirection')
    ORDER BY LocaleMessageTime ASC
  `);

  // build current-in-zone map
  const current = {};
  for (const evt of result.recordset) {
    const {
      EmployeeID,
      ObjectName1,
      PersonnelType,
      CardNumber,
      Dateonly,
      Swipe_Time,
      Direction,
      Door
    } = evt;

    let zone = mapDoorToZone(Door, Direction) || 'Unknown Zone';

    if (Direction === 'InDirection') {
      current[EmployeeID] = {
        Dateonly,
        Swipe_Time,
        EmployeeID,
        ObjectName1,
        CardNumber,
        PersonnelType,
        zone
      };
    } else {
      delete current[EmployeeID];
    }
  }

  // group by zone and build summary
  const zoneMap = {};
  for (const emp of Object.values(current)) {
    zoneMap[emp.zone] = zoneMap[emp.zone] || [];
    zoneMap[emp.zone].push(emp);
  }
  const summary = Object.entries(zoneMap).map(([zone, emps]) => ({
    zone,
    count: emps.length
  }));

  return {
    asOf: new Date().toISOString(),
    summary,
    details: zoneMap
  };
}

exports.getLiveOccupancy = async (req, res) => {
  try {
    await poolConnect;

    // Set up SSE headers
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive'
    });
    res.write('\n');

    // Immediately send first payload
    const send = async () => {
      try {
        const data = await fetchLiveOccupancyData();
        res.write(`data: ${JSON.stringify(data)}\n\n`);
      } catch (err) {
        console.error('Error fetching live occupancy for SSE:', err);
        // optionally send an error event
        res.write(`event: error\ndata: ${JSON.stringify({ error: 'Fetch failed' })}\n\n`);
      }
    };

    await send();
    // then every 5s
    const interval = setInterval(send, 5_000);

    // clean up on client disconnect
    req.on('close', () => {
      clearInterval(interval);
    });

  } catch (err) {
    console.error('Live occupancy SSE setup error:', err);
    res.status(500).json({ error: 'Internal Server Error' });
  }
};








// controllers/liveOccupancyController.js

const { poolConnect, pool } = require('../config/db');
// ← Import your real mapping function
const mapDoorToZone = require('../data/doorZoneMap');

exports.getLiveOccupancy = async (req, res) => {
  try {
    await poolConnect;
    const request = pool.request();

    // 1) Fetch Admit events with In/Out directions in the last 24h
    const result = await request.query(`
      WITH CombinedQuery AS (
        SELECT 
          DATEADD(MINUTE, -1 * t1.[MessageLocaleOffset], t1.[MessageUTC]) AS LocaleMessageTime,
          t1.ObjectName1,
          t1.PartitionName2 AS location,
          /* three-stage CardNumber resolution */
          COALESCE(
            TRY_CAST(t_xml.XmlMessage AS XML)
              .value('(/LogMessage/CHUID/Card)[1]', 'varchar(50)'),
            TRY_CAST(t_xml.XmlMessage AS XML)
              .value('(/LogMessage/CHUID)[1]', 'varchar(50)'),
            SCard.[value]
          ) AS CardNumber,
          t5_admit.value   AS AdmitCode,
          t5_dir.value     AS Direction,
          t1.ObjectName2   AS Door,
          CASE 
            WHEN t3.Name IN ('Contractor', 'Terminated Contractor') THEN t2.Text12
            ELSE CAST(t2.Int1 AS NVARCHAR)
          END               AS EmployeeID,
          t3.Name          AS PersonnelType,
          t5_rej.value     AS Rejection_Type
        FROM [ACVSUJournal_00010020].[dbo].[ACVSUJournalLog] AS t1
        LEFT JOIN [ACVSCore].[Access].[Personnel] AS t2
          ON t1.ObjectIdentity1 = t2.GUID
        LEFT JOIN [ACVSCore].[Access].[PersonnelType] AS t3
          ON t2.PersonnelTypeId = t3.ObjectID

        -- AdmitCode shredded
        LEFT JOIN [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred] AS t5_admit
          ON t1.XmlGUID = t5_admit.GUID
         AND t5_admit.Name = 'AdmitCode'

        -- In/Out Direction shredded
        LEFT JOIN [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred] AS t5_dir
          ON t1.XmlGUID = t5_dir.GUID
         AND t5_dir.Value IN ('InDirection', 'OutDirection')

        -- Full XML for CHUID/Card fallback
        LEFT JOIN [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxml] AS t_xml
          ON t1.XmlGUID = t_xml.GUID

        -- Pre-pulled shredded Card/CHUID row
        LEFT JOIN (
          SELECT GUID, [value]
          FROM [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred]
          WHERE [Name] IN ('Card', 'CHUID')
        ) AS SCard
          ON t1.XmlGUID = SCard.GUID

        -- Rejection code shredded
        LEFT JOIN [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred] AS t5_rej
          ON t1.XmlGUID = t5_rej.GUID
         AND t5_rej.Name = 'RejectCode'

        WHERE
          t1.MessageType IN ('CardAdmitted','CardRejected')
          AND t1.PartitionName2 = 'APAC.Default'
          -- keep all historic rows from Jan 1, 2025 onward
          AND CONVERT(date, DATEADD(MINUTE, -1 * t1.MessageLocaleOffset, t1.MessageUTC)) >= '2025-01-01'
      )

      SELECT
        CONVERT(VARCHAR(10), LocaleMessageTime, 23) AS Dateonly,
        CONVERT(VARCHAR(8),  LocaleMessageTime, 108) AS Swipe_Time,
        EmployeeID,
        ObjectName1,
        PersonnelType,
        CardNumber,
        AdmitCode,
        Direction,
        Door
      FROM CombinedQuery
      WHERE
        LocaleMessageTime >= DATEADD(HOUR, -24, GETDATE())
        AND AdmitCode = 'Admit'
        AND Direction IN ('InDirection','OutDirection')
      ORDER BY LocaleMessageTime ASC
    `);

    const events = result.recordset;

    // 2) Compute “current in-zone” by tracking In/Out
    const current = {};
    for (const evt of events) {
      const {
        EmployeeID,
        ObjectName1,
        PersonnelType,
        CardNumber,
        Dateonly,
        Swipe_Time,
        Direction,
        Door
      } = evt;

      // ← Pass both door & direction, coalescing null → "Unknown Zone"
      let zone = mapDoorToZone(Door, Direction);
      if (!zone) zone = 'Unknown Zone';

      if (Direction === 'InDirection') {
        current[EmployeeID] = {
          Dateonly,
          Swipe_Time,
          EmployeeID,
          ObjectName1,
          CardNumber,
          PersonnelType,
          zone
        };
      } else {
        delete current[EmployeeID];
      }
    }

    // 3) Group by zone
    const zoneMap = {};
    for (const emp of Object.values(current)) {
      zoneMap[emp.zone] = zoneMap[emp.zone] || [];
      zoneMap[emp.zone].push(emp);
    }

    // 4) Build summary
    const summary = Object.entries(zoneMap).map(([zone, emps]) => ({
      zone,
      count: emps.length
    }));

    // Return live occupancy
    res.json({
      asOf:   new Date().toISOString(),
      summary,
      details: zoneMap
    });
  } catch (err) {
    console.error('Live occupancy error:', err);
    res.status(500).json({ error: 'Internal Server Error' });
  }
};











// controllers/liveOccupancyController.js

const { poolConnect, pool, sql } = require('../config/db');
// import the real mapping function (with turnstile & direction logic)
const mapDoorToZone = require('../data/doorZoneMap');

exports.getLiveOccupancy = async (req, res) => {
  try {
    await poolConnect;
    const request = pool.request();

    // 1) Fetch Admit events with In/Out directions in the last 24h
    const result = await request.query(`
      WITH CombinedQuery AS (
        /* … your big query unchanged … */
      )
      SELECT
        CONVERT(VARCHAR(10), DATEADD(MINUTE, -1 * t1.[MessageLocaleOffset], t1.[MessageUTC]), 23) AS Dateonly,
        CONVERT(VARCHAR(8),  DATEADD(MINUTE, -1 * t1.[MessageLocaleOffset], t1.[MessageUTC]), 108) AS Swipe_Time,
        CASE 
          WHEN t3.Name IN ('Contractor', 'Terminated Contractor') THEN t2.Text12
          ELSE CAST(t2.Int1 AS NVARCHAR)
        END AS EmployeeID,
        t1.ObjectName1,
        t3.Name AS PersonnelType,
        COALESCE(
          TRY_CAST(t_xml.XmlMessage AS XML).value('(/LogMessage/CHUID/Card)[1]', 'varchar(50)'),
          TRY_CAST(t_xml.XmlMessage AS XML).value('(/LogMessage/CHUID)[1]', 'varchar(50)'),
          SCard.[value]
        ) AS CardNumber,
        t5_admit.value AS AdmitCode,
        t5_dir.value AS Direction,
        t1.ObjectName2 AS Door
      FROM
        [ACVSUJournal_00010020].[dbo].[ACVSUJournalLog] AS t1
        /* … all your JOINs unchanged … */
      WHERE
        t1.MessageType IN ('CardAdmitted', 'CardRejected')
        AND t1.PartitionName2 = 'APAC.Default'
      /* and your date filter */
    `);

    const events = result.recordset;

    // 2) Track current in‐zone employees
    const current = {};
    for (const evt of events) {
      const {
        EmployeeID,
        ObjectName1,
        PersonnelType,
        CardNumber,
        Dateonly,
        Swipe_Time,
        Direction,
        Door
      } = evt;

      // now using the imported function, and defaulting null back to "Unknown Zone"
      let zone = mapDoorToZone(Door, Direction);
      if (!zone) zone = 'Unknown Zone';

      if (Direction === 'InDirection') {
        current[EmployeeID] = {
          Dateonly,
          Swipe_Time,
          EmployeeID,
          ObjectName1,
          CardNumber,
          PersonnelType,
          zone
        };
      } else {
        delete current[EmployeeID];
      }
    }

    // 3) Group by zone
    const zoneMap = {};
    Object.values(current).forEach(emp => {
      zoneMap[emp.zone] = zoneMap[emp.zone] || [];
      zoneMap[emp.zone].push(emp);
    });

    // 4) Summary counts
    const summary = Object.entries(zoneMap).map(([zone, emps]) => ({
      zone,
      count: emps.length
    }));

    res.json({
      asOf: new Date().toISOString(),
      summary,
      details: zoneMap
    });
  } catch (err) {
    console.error('Live occupancy error:', err);
    res.status(500).json({ error: 'Internal Server Error' });
  }
};






// data/doorZoneMap.js

// … your doorZoneMap object unchanged …

function mapDoorToZone(door, direction) {
  // Direction‐based rule for turnstiles
  if (turnstilePrefixList.some(prefix => door.startsWith(prefix))) {
    return direction === 'InDirection' ? 'Reception Area' : null;
  }

  // exact match, or fall back to the literal key lookup
  return doorZoneMap[door] || 'Unknown Zone';
}

module.exports = mapDoorToZone;







Read all below files carefully . and Solve this issue .
Issue is When i run this http://localhost:5000/api/live-occupancy
 We {
  "asOf": "2025-05-15T21:25:06.435Z",
  "summary": [
    {
      "zone": "Unknown Zone",
      "count": 6
    }
  ],
  "details": {
    "Unknown Zone": [
      {
        "Dateonly": "2025-05-16",
        "Swipe_Time": "01:58:04",
        "EmployeeID": "0",
        "ObjectName1": "Vasulkar, Sachin",
        "CardNumber": "410317",
        "PersonnelType": "Property Management",
        "zone": "Unknown Zone"
      },
      {
        "Dateonly": "2025-05-15",
        "Swipe_Time": "16:57:35",
        "EmployeeID": "312704",
        "ObjectName1": "Dalvi, Mohini Atmaram",
        "CardNumber": "604963",
        "PersonnelType": "Employee",
        "zone": "Unknown Zone"
      },



This Responec issue is Door Present in doorZoneMap and incomming door are not matches thats why umkown zone retuns .
find the root cause of this issue and solve this issue and give me updated js file carefully.

file 1

// controllers/liveOccupancyController.js

const { poolConnect, pool, sql } = require('../config/db');
const doorZoneMap = require('../data/doorZoneMap');

/**
 * Map a raw Door string to its Zone via your lookup table,
 * falling back to substring match or “Unknown Zone.”
 */
function mapDoorToZone(door) {
  if (doorZoneMap[door]) {
    return doorZoneMap[door];
  }
  // fallback: find a key contained in the door string
  for (const key of Object.keys(doorZoneMap)) {
    if (door.includes(key)) {
      return doorZoneMap[key];
    }
  }
  return 'Unknown Zone';
}

exports.getLiveOccupancy = async (req, res) => {
  try {
    await poolConnect;
    const request = pool.request();

    // 1) Fetch Admit events with In/Out directions in the last 24h
    const result = await request.query(`
        WITH CombinedQuery AS(
		SELECT 
	    DATEADD(MINUTE, -1 * t1.[MessageLocaleOffset], t1.[MessageUTC]) AS LocaleMessageTime,
    t1.ObjectName1,
	t1.PartitionName2 As location,
	t5_card.CardNumber,
t5_admit.value AS AdmitCode,
t5_dir.value AS Direction,
    t1.ObjectName2,
	t5_rej.value AS Rejection_Type,
	CASE 
        WHEN t3.Name IN ('Contractor', 'Terminated Contractor') THEN t2.Text12
        ELSE CAST(t2.Int1 AS NVARCHAR)
    END AS "EmployeeID",
    t3.Name AS PersonnelType,
    t1.MessageType,t1.XmlGUID
	FROM
    [ACVSUJournal_00010020].[dbo].[ACVSUJournalLog] AS t1
LEFT JOIN
    [ACVSCore].[Access].[Personnel] AS t2
    ON t1.ObjectIdentity1 = t2.GUID
LEFT JOIN
    [ACVSCore].[Access].[PersonnelType] AS t3
    ON t2.[PersonnelTypeId] = t3.[ObjectID]
LEFT JOIN
    [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred] AS t5_admit
    ON t1.XmlGUID = t5_admit.GUID
    AND t5_admit.Name = 'AdmitCode'
LEFT JOIN
    [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred] AS t5_dir
    ON t1.XmlGUID = t5_dir.GUID
    AND t5_dir.Value IN ('InDirection', 'OutDirection')
    LEFT JOIN [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxml] AS t_xml
        ON t1.XmlGUID = t_xml.GUID
    -- Pre-pull shredded “Card” row
    LEFT JOIN (
    SELECT GUID, [value]
    FROM [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred]
    WHERE [Name] IN ('Card', 'CHUID')
    ) AS SCard
    ON t1.XmlGUID = SCard.GUID
    /* NEW: three-stage CardNumber resolution */
    OUTER APPLY (
    SELECT COALESCE(
        -- 1) <LogMessage><CHUID><Card>…</Card></CHUID>
        TRY_CAST(t_xml.XmlMessage AS XML)
        .value('(/LogMessage/CHUID/Card)[1]', 'varchar(50)'),
        -- 2) <LogMessage><CHUID>…</CHUID> (no nested <Card>)
        TRY_CAST(t_xml.XmlMessage AS XML)
        .value('(/LogMessage/CHUID)[1]', 'varchar(50)'),
        -- 3) shredded fallback
        SCard.[value]
    ) AS CardNumber
    ) AS t5_card
 
LEFT JOIN
    [ACVSUJournal_00010020].[dbo].[ACVSUJournalLogxmlShred] AS t5_Rej
    ON t1.XmlGUID = t5_Rej.GUID
    AND t5_Rej.Name = 'RejectCode'
 
   
   --include both admits and rejects
   WHERE t1.MessageType IN ('CardAdmitted', 'CardRejected')
   AND t1.PartitionName2 = 'APAC.Default'
   AND CONVERT(date, DATEADD(MINUTE, -1 * t1.MessageLocaleOffset, t1.MessageUTC)) >= '2025-01-01')


     SELECT
        CONVERT(VARCHAR(10), LocaleMessageTime, 23) AS Dateonly,
        CONVERT(VARCHAR(8),  LocaleMessageTime, 108) AS Swipe_Time,
        EmployeeID,
        ObjectName1,
        PersonnelType,
        CardNumber,
        AdmitCode,
        Direction,
        ObjectName2 AS Door
      FROM CombinedQuery
      WHERE 
        LocaleMessageTime >= DATEADD(HOUR, -24, GETDATE()) AND
        AdmitCode = 'Admit' AND
        Direction IN ('InDirection','OutDirection')
      ORDER BY LocaleMessageTime ASC;
    `);

    const events = result.recordset;

    // 2) Track current in‐zone employees
    const current = {};
    for (const evt of events) {
      const {
        EmployeeID,
        ObjectName1,
        PersonnelType,
        CardNumber,
        Dateonly,
        Swipe_Time,
        Direction,
        Door
      } = evt;

      const zone = mapDoorToZone(Door);

      if (Direction === 'InDirection') {
        current[EmployeeID] = {
          Dateonly,
          Swipe_Time,
          EmployeeID,
          ObjectName1,
          CardNumber,
          PersonnelType,
          zone
        };
      } else {
        delete current[EmployeeID];
      }
    }

    // 3) Group by zone
    const zoneMap = {};
    Object.values(current).forEach(emp => {
      zoneMap[emp.zone] = zoneMap[emp.zone] || [];
      zoneMap[emp.zone].push(emp);
    });

    // 4) Summary counts
    const summary = Object.entries(zoneMap).map(([zone, emps]) => ({
      zone,
      count: emps.length
    }));

    res.json({
      asOf: new Date().toISOString(),
      summary,
      details: zoneMap
    });
  } catch (err) {
    console.error('Live occupancy error:', err);
    res.status(500).json({ error: 'Internal Server Error' });
  }
};


file 2


// data/doorZoneMap.js

const doorZoneMap = {
  "APAC_IN-PUN-PODIUM-RED-RECREATION AREA FIRE EXIT 1-DOOR": "Red Zone",
  "APAC_IN_PUN_PODIUM_RED_IDF ROOM-02-Restricted Door": "Red Zone",
  "APAC_IN-PUN-PODIUM-MAIN PODIUM LEFT ENTRY-DOOR": "Reception Area",
  "APAC_IN_PUN_PODIUM_MAIN PODIUM RIGHT ENTRY-DOOR": "Reception Area",
  "APAC_IN-PUN-PODIUM-RED-RECEPTION TO WS ENTRY 1-DOOR": "Red Zone",
  "APAC_IN_PUN_PODIUM_ST2 DOOR 1 (RED)": "Red Zone",
  "APAC_IN_PUN_PODIUM_RED_MAIN LIFT LOBBY ENTRY 1-DOOR": "Red Zone",
  "APAC_IN_PUN_PODIUM_ST 1-DOOR 1 (RED)": "Red Zone",
  "APAC_IN-PUN-PODIUM-YELLOW- SERVICE PASSAGE 1 ENTRY-DOOR": "YELLOW Zone",
  "APAC_IN-PUN-PODIUM-YELLOW-MAIN LIFT LOBBY-DOOR": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_ST2 DOOR 2 (YELLOW)": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_YELLOW_MDF Restricted Door": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_YELLOW_IT STORE ROOM-DOOR Restricted door": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_GSOC DOOR Restricted door": "GSOC",
  "APAC_IN_PUN_PODIUM_YELLOW_REPRO STORE-DOOR Restricted door": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_YELLOW_CONTROL PANEL ROOM-DOOR Restricted door": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_YELLOW_PREACTION ROOM-DOOR Restricted door": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_YELLOW_RECEPTION ENTRY-DOOR": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_YELLOW_TESTING LAB-DOOR Restricted door": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_GREEN-_IDF ROOM 1-Restricted Door": "GREEN Zone",
  "APAC_IN_PUN_PODIUM_GREEN_UPS ENTRY 1-DOOR Restricted door": "GREEN Zone",
  "APAC_IN_PUN_PODIUM_GREEN_UPS ENTRY 2-DOOR Restricted door": "GREEN Zone",
  "APAC_IN_PUN_PODIUM_GREEN_LOCKER HR STORE 3-DOOR Restricted door": "GREEN Zone",
  "APAC_IN_PUN_PODIUM_ST4 DOOR 2 (GREEN)": "GREEN Zone",
  "APAC_IN_PUN_PODIUM_ST4 DOOR 1 (ORANGE)": "ORANGE Zone",
  "APAC_IN_PUN_PODIUM_GREEN-MAIN LIFT LOBBY-DOOR": "GREEN Zone",
  "APAC_IN_PUN_PODIUM_ST3 DOOR 2 (GREEN)": "GREEN Zone",
  "APAC_IN_PUN_PODIUM_GREEN_RECEPTION ENTRY-DOOR": "GREEN Zone",
  "APAC_IN_PUN_PODIUM_ORANGE_RECEPTION ENTRY-DOOR": "ORANGE Zone",
  "APAC_IN_PUN_PODIUM_ST3_DOOR 1 (ORANGE)": "ORANGE Zone",
  "APAC_IN_PUN_PODIUM_ORANGE_MAIN LIFT LOBBY-DOOR": "ORANGE Zone",
  "APAC_IN_PUN_PODIUM_ORANGE-IDF ROOM 3-Restricted Door": "ORANGE Zone",
  "APAC_IN_PUN_PODIUM_ORANGE_KITCHENETTE FIRE EXIT-DOOR": "ORANGE Zone",
  "APAC_IN_PUN_2NDFLR_IDF ROOM_10:05:86 Restricted Door": "2nd Floor Pune",
  "APAC_IN_PUN_2NDFLR_UPS/ELEC ROOM Restricted Door_10:05:FE": "2nd Floor Pune",
  "APAC_IN_PUN_2NDFLR_RECPTION TO WORKSTATION DOOR_10:05:4B": "2nd Floor Pune",
  "APAC_IN_PUN_2NDFLR_LIFTLOBBY TO RECEPTION EMTRY DOOR_10:05:74": "2nd Floor Pune",
  "APAC_IN_PUN_2NDFLR_LIFTLOBBY TO WORKSTATION DOOR_10:05:F0": "2nd Floor Pune",
  "APAC_IN_PUN_PODIUM_RED_RECEPTION TO WS ENTRY 1-DOOR NEW": "Red Zone",
  "APAC_IN_PUN_PODIUM_YELLOW_MAIN LIFT LOBBY-DOOR NEW": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_ST 1 DOOR 2 (YELLOW)": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_ORANGE_KITCHENETTE FIRE EXIT-DOOR NEW": "ORANGE Zone",
  "APAC_IN_PUN_PODIUM_YELLOW_FIRE EXIT 1-DOOR NEW": "YELLOW Zone",
  "APAC_IN_PUN_PODIUM_RED_RECREATION AREA FIRE EXIT 1-DOOR NEW": "Red Zone",
  "APAC_IN_PUN_PODIUM_MAIN PODIUM RIGHT ENTRY-DOOR NEW": "Reception Area",
  "APAC_IN_PUN_PODIUM_MAIN PODIUM LEFT ENTRY-DOOR NEW": "Reception Area",
  "APAC_IN_PUN_TOWER B_MAIN RECEPTION DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_LIFT LOBBY DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_ST6_GYM SIDE DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_ST6_WKS SIDE DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_ST5_KAPIL DEV DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_ST5_WKS SIDE DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_RECEPTION LEFT DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_RECEPTION RIGHT DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_ST5_FIRE EXIT DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_ST6_FIRE EXIT DOOR": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_IBMS ROOM": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_UPS ROOM": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_MDF ROOM": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_PAC ROOM": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_IT STORE ROOM": "TOWER B Pune",
  "APAC_IN_PUN_TOWER B_GYM ROOM": "TOWER B Pune"
};

// Special door prefixes for dynamic direction-based mapping
const turnstilePrefixList = [
  "APAC_IN_PUN_PODIUM_P-1 TURNSTILE",
  "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 1-OUT DOOR",
  "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 2 -OUT DOOR",
  "APAC_IN_PUN-PODIUM_P-1 TURNSTILE 3 -OUT DOOR",
  "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 4 -OUT DOOR"
];

function mapDoorToZone(door, direction) {
  // Direction-based rule for turnstiles
  if (turnstilePrefixList.some(prefix => door.startsWith(prefix))) {
    return direction === 'InDirection' ? 'Reception Area' : null;
  }

  return doorZoneMap[door] || 'Unknown';
}

module.exports = mapDoorToZone;



file 3


// routes/liveOccupancyRoutes.js

const express = require('express');
const router  = express.Router();
const { getLiveOccupancy } = require('../controllers/liveOccupancyController');

router.get('/live-occupancy', getLiveOccupancy);

module.exports = router;



